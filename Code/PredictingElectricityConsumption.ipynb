{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this repository is to find a regression approach that can be used to predict electricity consumption from residential unit and household data. We have extracted the information from the [2009 version of the RECS program](https://www.eia.gov/consumption/residential/data/2009/index.php?view=microdata).\n",
    "\n",
    "We start with the data processing step, then the creation of a training set and a test set, then use two selected regression frameworks, and end with a few concluding remarks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Many columns of the table have categorical data.\n",
    "We use One-hot encoding schema and another approach, as will be explained below, to convert this data to binary.\n",
    "\n",
    "Data leakage is prevented by removing columns that are directly related to the electricity consumption (KWH). \n",
    "Specifically, columns from 'KWHSPH' to 'DOLELRFG' are directly related to electricity usage and electricity cost.\n",
    "Also, columns from 'TOTALBTU' to 'TOTALDOLOTH' are composed of total energy consumption of different types. \n",
    "The presence of these columns in the data leads to abnormally high precisions when applying some regression frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n",
      "/root/Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/envs/Zesty/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (717,718) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KWH</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT14</th>\n",
       "      <th>...</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOEID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18466</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5148</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2218</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2869</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>7647</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12080</th>\n",
       "      <td>1813</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12081</th>\n",
       "      <td>9834</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>4800</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>1764</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12083 rows Ã— 2580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         KWH  AGEHHMEMCAT10  AGEHHMEMCAT10  AGEHHMEMCAT11  AGEHHMEMCAT11  \\\n",
       "DOEID                                                                      \n",
       "1      18466       2.526316            1.0       2.181818            1.0   \n",
       "2       5148       2.526316            1.0       2.181818            1.0   \n",
       "3       2218       2.526316            1.0       2.181818            1.0   \n",
       "4      10015       2.526316            1.0       2.181818            1.0   \n",
       "5       2869       2.526316            1.0       2.181818            1.0   \n",
       "...      ...            ...            ...            ...            ...   \n",
       "12079   7647       2.526316            1.0       2.181818            1.0   \n",
       "12080   1813       2.526316            1.0       2.181818            1.0   \n",
       "12081   9834       2.526316            1.0       2.181818            1.0   \n",
       "12082   4800       2.526316            1.0       2.181818            1.0   \n",
       "12083   1764       2.526316            1.0       2.181818            1.0   \n",
       "\n",
       "       AGEHHMEMCAT12  AGEHHMEMCAT12  AGEHHMEMCAT13  AGEHHMEMCAT13  \\\n",
       "DOEID                                                               \n",
       "1           1.833333            1.0           1.25            1.0   \n",
       "2           1.833333            1.0           1.25            1.0   \n",
       "3           1.833333            1.0           1.25            1.0   \n",
       "4           1.833333            1.0           1.25            1.0   \n",
       "5           1.833333            1.0           1.25            1.0   \n",
       "...              ...            ...            ...            ...   \n",
       "12079       1.833333            1.0           1.25            1.0   \n",
       "12080       1.833333            1.0           1.25            1.0   \n",
       "12081       1.833333            1.0           1.25            1.0   \n",
       "12082       1.833333            1.0           1.25            1.0   \n",
       "12083       1.833333            1.0           1.25            1.0   \n",
       "\n",
       "       AGEHHMEMCAT14  ...  2376  2377  2378  2379  2380  2381  2382  2383  \\\n",
       "DOEID                 ...                                                   \n",
       "1                  1  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n",
       "2                  1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "3                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "4                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "5                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "...              ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "12079              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12080              1  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12081              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12082              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "12083              1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       2384  2385  \n",
       "DOEID              \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "5       0.0   0.0  \n",
       "...     ...   ...  \n",
       "12079   1.0   0.0  \n",
       "12080   0.0   0.0  \n",
       "12081   1.0   0.0  \n",
       "12082   0.0   0.0  \n",
       "12083   0.0   0.0  \n",
       "\n",
       "[12083 rows x 2580 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd Data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv(\"recs2009_public.csv\",index_col=0)\n",
    "\n",
    "\n",
    "# There are many columns showing parameters like \"temperature when...\", but showing -2 when not applicable.\n",
    "# We need to separate this type of data into a binary (not applicable or applicable) and a non-categorical column\n",
    "# In the non-categorical column, we will replace \"-2\" with the average of all the values larger than 0\n",
    "\n",
    "def seriesIntoBinaryAndNonCateg(s,valuesToBinary):\n",
    "    mean = s[~s.isin(valuesToBinary)].mean()\n",
    "    nonCategSeries = s.replace(valuesToBinary,mean)\n",
    "    categSeriesList = [(s == value).astype(float) for value in valuesToBinary]\n",
    "    return pd.concat([nonCategSeries]+categSeriesList,axis=1)\n",
    "\n",
    "cols_categ_with_binary = set([21,22,26,29,38,41,44,48,54,146,152,310,460,462,466,467,468,540,546,547,548,549,\n",
    "                          600,602,716,723,776]+list(range(760,773)))\n",
    "\n",
    "list_all_noncateg_and_binary = list()\n",
    "for col in cols_categ_with_binary:\n",
    "    # I found columns with \".\" that I am assuming to mean \"again -2\"\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2))\n",
    "    list_all_noncateg_and_binary.append(seriesIntoBinaryAndNonCateg(s,[-2]))\n",
    "df_all_noncateg_and_binary = pd.concat(list_all_noncateg_and_binary,axis=1)\n",
    "\n",
    "# In the case of column \"NKRGALNC\", 77 means \"not sure\". thus we have values -2 and 77 to trasnform to binary\n",
    "# and a non-categorical integer \n",
    "\n",
    "s = pd.to_numeric(df[df.columns[717]].replace('.',-2)) # Asumming \".\" is \"-2\" to save time\n",
    "ds_717 = seriesIntoBinaryAndNonCateg(s,[-2,77])\n",
    "\n",
    "# In a similar way, columns 595 597 599 601, can be trasnform into a non-categorical column and 3 binary columns \n",
    "# corresponding to values -2, -8, -9\n",
    "\n",
    "cols_noncateg_and_3_binaries = {595,597,599,601}\n",
    "list_all_noncateg_and_3_binaries = list()\n",
    "for col in cols_noncateg_and_3_binaries:\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2)) # Asumming \".\" is \"-2\" to save time\n",
    "    list_all_noncateg_and_3_binaries.append(seriesIntoBinaryAndNonCateg(s,[-2,-8,-9]))\n",
    "\n",
    "df_all_noncateg_and_3_binaries = pd.concat(list_all_noncateg_and_3_binaries,axis=1)\n",
    "    \n",
    "# We create a list of fully non-categorical columns, as most columns are categorical\n",
    "cols_full_noncateg=set([4,5,6,7,8,15,30,31,32,33,113,115,117,133,238,288,502,503,556,594,596,598,607,758,759,784] \n",
    "                    +list(range(826,836))+list(range(856,906))+list(range(931,939)))\n",
    "df_full_noncateg=df[df.columns[list(cols_full_noncateg)]]\n",
    "\n",
    "# The gloal is predicting electricity usage from residential unit information so we remove all columns that\n",
    "# give direct information about electricity usage, and electricity cost (from 'KWHSPH' to 'DOLELRFG'). \n",
    "# Also, we have removed columns reflecting total energy consumption (from 'TOTALBTU' to 'TOTALDOLOTH').\n",
    "cols_to_ignore = set(list(range(839,856))+list(set(range(906,918))))\n",
    "\n",
    "# The raminig columns correspond to the full categorical ones.\n",
    "cols_full_categ = [col for col in range(len(df.columns)) if col not in cols_categ_with_binary \\\n",
    "                     and col not in cols_full_noncateg and col not in cols_noncateg_and_3_binaries \\\n",
    "                     and col != 717 and col not in cols_to_ignore and col != 838] # 838 is the column to be predcited\n",
    "\n",
    "# We now start with the actual One-hot econding schema.\n",
    "df_categorical = df[df.columns[cols_full_categ]]\n",
    "X = df_categorical.to_numpy().tolist()\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X)\n",
    "Y = enc.transform(X).toarray()\n",
    "df_binary = pd.DataFrame(Y, index=df.index)\n",
    "\n",
    "# Finally concatenate all the dataframes.\n",
    "df_encoded = pd.concat([df[df.columns[838]],df_all_noncateg_and_binary,ds_717,df_all_noncateg_and_3_binaries,df_full_noncateg,df_binary],axis=1)\n",
    "df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training set and a test set\n",
    "\n",
    "We create a training and a test set, using a random approach.\n",
    "We will only use the test set when the models are complete in order to validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop([\"KWH\"],axis =1).to_numpy()\n",
    "y = df_encoded[\"KWH\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Because of the nature of the data, we expect it to be stochastic to some extent. \n",
    "We start using random forest because of its simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Diff: 5931.193861561492\n",
      "Standard Deviation of y_test: 7107.848939035486\n",
      "Root Mean Square Error:  6386.42650274541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 250,max_depth=3,random_state=0, criterion=\"entropy\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(\"Standard Deviation of Diff:\",np.std(prediction-y_test))     # See conclusions\n",
    "print(\"Standard Deviation of y_test:\", np.std(y_test))             # See conclusions\n",
    "print(\"Root Mean Square Error: \",mean_squared_error(y_test, prediction, squared=False)) # Returns RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regressor\n",
    "\n",
    "Another method that is effective with stochastically distributed variables is the gaussian process regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Diff: 5001.419411073517\n",
      "Standard Deviation of y_test: 7107.848939035486\n",
      "Root Mean Square Error:  5005.4443014970175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(X_train, y_train)\n",
    "\n",
    "prediction = gpr.predict(X_test)\n",
    "print(\"Standard Deviation of Diff:\",np.std(prediction-y_test))     # See conclusions\n",
    "print(\"Standard Deviation of y_test:\", np.std(y_test))             # See conclusions\n",
    "print(\"Root Mean Square Error: \",mean_squared_error(y_test, prediction, squared=False)) # Returns RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "We use the root mean square error as a measure of the error of the prediction, and the standard deviation of the difference between the true values and the predicted corresponding values as a sanity check. This is, if the standard deviation of 'prediction-y_test' is lower than the standard deviation of 'y_test', the prediction is being successful to some extent.\n",
    "\n",
    "Both the random forest classifier and the Gaussian process regressor predict to some extent the electricity consumption. The latter is considerably better at making this prediction. However, none of the two models is exceptionally good and further exploration is necessary. These two models may serve as the\n",
    "first two benchmark models to eventually obtain an optimal solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
