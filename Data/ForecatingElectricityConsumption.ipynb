{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING\n",
    "\n",
    "Many columns of the table have categorical data.\n",
    "We use One-hot econding schema to convert this data to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/envs/Zesty/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (717,718) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KWH</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT14</th>\n",
       "      <th>...</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOEID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18466</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5148</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2218</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2869</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>7647</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12080</th>\n",
       "      <td>1813</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12081</th>\n",
       "      <td>9834</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>4800</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>1764</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12083 rows Ã— 2580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         KWH  AGEHHMEMCAT10  AGEHHMEMCAT10  AGEHHMEMCAT11  AGEHHMEMCAT11  \\\n",
       "DOEID                                                                      \n",
       "1      18466       2.526316            1.0       2.181818            1.0   \n",
       "2       5148       2.526316            1.0       2.181818            1.0   \n",
       "3       2218       2.526316            1.0       2.181818            1.0   \n",
       "4      10015       2.526316            1.0       2.181818            1.0   \n",
       "5       2869       2.526316            1.0       2.181818            1.0   \n",
       "...      ...            ...            ...            ...            ...   \n",
       "12079   7647       2.526316            1.0       2.181818            1.0   \n",
       "12080   1813       2.526316            1.0       2.181818            1.0   \n",
       "12081   9834       2.526316            1.0       2.181818            1.0   \n",
       "12082   4800       2.526316            1.0       2.181818            1.0   \n",
       "12083   1764       2.526316            1.0       2.181818            1.0   \n",
       "\n",
       "       AGEHHMEMCAT12  AGEHHMEMCAT12  AGEHHMEMCAT13  AGEHHMEMCAT13  \\\n",
       "DOEID                                                               \n",
       "1           1.833333            1.0           1.25            1.0   \n",
       "2           1.833333            1.0           1.25            1.0   \n",
       "3           1.833333            1.0           1.25            1.0   \n",
       "4           1.833333            1.0           1.25            1.0   \n",
       "5           1.833333            1.0           1.25            1.0   \n",
       "...              ...            ...            ...            ...   \n",
       "12079       1.833333            1.0           1.25            1.0   \n",
       "12080       1.833333            1.0           1.25            1.0   \n",
       "12081       1.833333            1.0           1.25            1.0   \n",
       "12082       1.833333            1.0           1.25            1.0   \n",
       "12083       1.833333            1.0           1.25            1.0   \n",
       "\n",
       "       AGEHHMEMCAT14  ...  2376  2377  2378  2379  2380  2381  2382  2383  \\\n",
       "DOEID                 ...                                                   \n",
       "1                  1  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n",
       "2                  1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "3                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "4                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "5                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "...              ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "12079              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12080              1  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12081              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12082              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "12083              1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       2384  2385  \n",
       "DOEID              \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "5       0.0   0.0  \n",
       "...     ...   ...  \n",
       "12079   1.0   0.0  \n",
       "12080   0.0   0.0  \n",
       "12081   1.0   0.0  \n",
       "12082   0.0   0.0  \n",
       "12083   0.0   0.0  \n",
       "\n",
       "[12083 rows x 2580 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv(\"recs2009_public.csv\",index_col=0)\n",
    "\n",
    "#There are many columns showing parameters like \"temperature when...\", but showing -2 when not aplicable.\n",
    "#We need to separate this type of data into a binary (not aplicable or aplicable) and a non-categorical column\n",
    "#In the non-categorical column, we will replace \"-2\" with the average of all the values different from \"-2\"\n",
    "\n",
    "def seriesIntoBinaryAndNonCateg(s,valuesToBinary):\n",
    "    mean = s[s > 0].mean()\n",
    "    nonCategSeries = s.replace(valuesToBinary,mean)\n",
    "    categSeriesList = [(s == value).astype(float) for value in valuesToBinary]\n",
    "    return pd.concat([nonCategSeries]+categSeriesList,axis=1)\n",
    "\n",
    "cols_categ_with_binary = set([21,22,26,29,38,41,44,48,54,146,152,310,460,462,466,467,468,540,546,547,548,549,\n",
    "                          600,602,716,723,776]+list(range(760,773)))\n",
    "list_all_noncateg_and_binary = list()\n",
    "for col in cols_categ_with_binary:\n",
    "    #I found columns with \".\" that I am assuming to mean \"again -2\"\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2))\n",
    "    list_all_noncateg_and_binary.append(seriesIntoBinaryAndNonCateg(s,[-2]))\n",
    "\n",
    "df_all_noncateg_and_binary = pd.concat(list_all_noncateg_and_binary,axis=1)\n",
    "\n",
    "#In the case of column \"NKRGALNC\", 77 means \"not sure\". thus we have values -2 and 77 to trasnform to binary\n",
    "#And a non-categorical integer\n",
    "#in the same way \n",
    "\n",
    "s = pd.to_numeric(df[df.columns[717]].replace('.',-2)) #asumming \".\" is \"-2\" to save time\n",
    "df_717 = seriesIntoBinaryAndNonCateg(s,[-2,77])\n",
    "\n",
    "#In a similar way, columns 595 597 599 601, can be trasnform into a non-categorical column and 3 binary columns \n",
    "#corresponding to values -2, -8, -9\n",
    "\n",
    "cols_noncateg_and_3_binaries = {595,597,599,601}\n",
    "list_all_noncateg_and_3_binaries = list()\n",
    "for col in cols_noncateg_and_3_binaries:\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2)) #asumming \".\" is \"-2\" to save time\n",
    "    list_all_noncateg_and_3_binaries.append(seriesIntoBinaryAndNonCateg(s,[-2,-8,-9]))\n",
    "\n",
    "df_all_noncateg_and_3_binaries = pd.concat(list_all_noncateg_and_3_binaries,axis=1)\n",
    "    \n",
    "# We create a list of fully non-categorical columns, as most columns are categorical\n",
    "cols_full_noncateg=set([4,5,6,7,8,15,30,31,32,33,113,115,117,133,238,288,502,503,556,594,596,598,607,758,759,784] \n",
    "                    +list(range(826,836))+list(range(856,906))+list(range(931,939)))\n",
    "df_full_noncateg=df[df.columns[list(cols_full_noncateg)]]\n",
    "# The gloal is predicting electricity usage from residential unit information so we remove all columns that\n",
    "# give direct information about electricity usage, and electricity cost 'KWHSPH'...'DOLELRFG'\n",
    "cols_to_ignore = set(list(range(839,856))+list(set(range(906,918))))\n",
    "\n",
    "#the raminig columns correspond to the full categorical ones\n",
    "cols_full_categ = [col for col in range(len(df.columns)) if col not in cols_categ_with_binary \\\n",
    "                     and col not in cols_full_noncateg and col not in cols_noncateg_and_3_binaries \\\n",
    "                     and col != 717 and col not in cols_to_ignore and col != 838] #838 is the column to be predcited\n",
    "\n",
    "#We now start with the actual One-hot econding schema\n",
    "df_categorical = df[df.columns[cols_full_categ]]\n",
    "X = df_categorical.to_numpy().tolist()\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X)\n",
    "Y = enc.transform(X).toarray()\n",
    "df_binary = pd.concat([pd.DataFrame(Y),pd.DataFrame(df.index)],axis =1).set_index(\"DOEID\")\n",
    "\n",
    "#finally concatenate all the dataframes\n",
    "df_encoded = pd.concat([df[df.columns[838]],df_all_noncateg_and_binary,df_717,df_all_noncateg_and_3_binaries,df_full_noncateg,df_binary],axis=1)\n",
    "df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a training set and a test set\n",
    "\n",
    "We create a training and a test set, using a random approach.\n",
    "We will only use the test set when the models are complete in order to validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.62% of the data correspond to the test set\n",
      "80.38% of the data correspond to the traning set\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "msk = np.random.rand(len(df_encoded)) < 0.8\n",
    "df_training = df_encoded[msk]\n",
    "df_test = df_encoded[~msk]\n",
    "\n",
    "testProcentageOfData = len(df_test.index)/(len(df_training.index)+len(df_test.index))*100\n",
    "traningProcentageofData = 100 - testProcentageOfData\n",
    "print(\"{:.2f}\".format(testProcentageOfData)+\"% of the data correspond to the test set\")\n",
    "print(\"{:.2f}\".format(traningProcentageofData)+\"% of the data correspond to the traning set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "Because of the nature of the data, I expect it to be stochastic to some extent. \n",
    "Thus, we start using random forest because of its simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6327.297343153065\n",
      "7521.243897098164\n",
      "4567.146665412303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#We now create dataframes for the input and output data of the model\n",
    "#I am assuming all other columns can be used as input, for simplicity.\n",
    "df_X = df_training.drop([\"KWH\"],axis =1) \n",
    "df_Y = df_training[\"KWH\"]\n",
    "clf = RandomForestClassifier(n_estimators = 110,max_depth=3,random_state=0, criterion=\"entropy\")\n",
    "clf.fit(df_X.to_numpy(), df_Y.to_numpy())\n",
    "\n",
    "prediction = clf.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "print(np.std(diff))\n",
    "print(np.std(df_test[\"KWH\"].to_numpy()))\n",
    "print(np.std(prediction))\n",
    "#print(np.std(df_test[\"KWH\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Regressor\n",
    "\n",
    "Another method that is effective with stochastically variables is the gaussian process regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, ConstantKernel, RBF\n",
    "\n",
    "\n",
    "df_X = df_training.drop([\"KWH\"],axis =1) \n",
    "df_Y = df_training[\"KWH\"]\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(df_X.to_numpy(), df_Y.to_numpy())\n",
    "prediction = gpr.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "\n",
    "#print(prediction)\n",
    "print(np.std(diff))\n",
    "print(np.std(df_test[\"KWH\"].to_numpy()))\n",
    "print(np.std(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "I am obtaining a very high precision with Gaussian Process Regression.\n",
    "However, it could mean that a given variable in the data is closely resembling the electricy consumption\n",
    "\n",
    "\n",
    "If I had more time, I would try to find out why the precision of the second model is so high. Am I including data that reflect partical consumption of electricty, and add up to the final consumption? I tryied to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-006942260d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDotProduct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhiteKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDotProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWhiteKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KWH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KWH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_training' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "df_X = df_training.drop([\"KWH\"],axis =1) \n",
    "df_Y = df_training[\"KWH\"]\n",
    "\n",
    "a = list()\n",
    "for col in df_X.columns:\n",
    "    if len(df_X[col].to_numpy().shape) > 1:\n",
    "        X = df_X[col].to_numpy()\n",
    "        X = [x[0] for x in X]\n",
    "        Y = [y for y in df_Y]\n",
    "        c = np.corrcoef(X,Y)\n",
    "        if not np.isnan(c[0][1]):\n",
    "            a.append((c[0][1],col))\n",
    "    else:\n",
    "        #X = np.array([value for value in df_X[col].to_numpy()])\n",
    "        a.append((df_X[col].corr(df_Y),col))\n",
    "        \n",
    "print(sorted(a,reverse=True))\n",
    "        \n",
    "    #print(X.shape)\n",
    "    #gpr = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(X, df_Y.to_numpy())\n",
    "    #prediction = gpr.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "    #diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "    #print(np.std(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOEID\n",
      "1        18466\n",
      "2         5148\n",
      "3         2218\n",
      "4        10015\n",
      "5         2869\n",
      "         ...  \n",
      "12079     7647\n",
      "12080     1813\n",
      "12081     9834\n",
      "12082     4800\n",
      "12083     1764\n",
      "Name: KWH, Length: 12083, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         KWH  AGEHHMEMCAT10  AGEHHMEMCAT10  AGEHHMEMCAT11  AGEHHMEMCAT11  \\\n",
      "DOEID                                                                      \n",
      "1      18466       2.526316            1.0       2.181818            1.0   \n",
      "2       5148       2.526316            1.0       2.181818            1.0   \n",
      "3       2218       2.526316            1.0       2.181818            1.0   \n",
      "4      10015       2.526316            1.0       2.181818            1.0   \n",
      "5       2869       2.526316            1.0       2.181818            1.0   \n",
      "...      ...            ...            ...            ...            ...   \n",
      "12079   7647       2.526316            1.0       2.181818            1.0   \n",
      "12080   1813       2.526316            1.0       2.181818            1.0   \n",
      "12081   9834       2.526316            1.0       2.181818            1.0   \n",
      "12082   4800       2.526316            1.0       2.181818            1.0   \n",
      "12083   1764       2.526316            1.0       2.181818            1.0   \n",
      "\n",
      "       AGEHHMEMCAT12  AGEHHMEMCAT12  AGEHHMEMCAT13  AGEHHMEMCAT13  \\\n",
      "DOEID                                                               \n",
      "1           1.833333            1.0           1.25            1.0   \n",
      "2           1.833333            1.0           1.25            1.0   \n",
      "3           1.833333            1.0           1.25            1.0   \n",
      "4           1.833333            1.0           1.25            1.0   \n",
      "5           1.833333            1.0           1.25            1.0   \n",
      "...              ...            ...            ...            ...   \n",
      "12079       1.833333            1.0           1.25            1.0   \n",
      "12080       1.833333            1.0           1.25            1.0   \n",
      "12081       1.833333            1.0           1.25            1.0   \n",
      "12082       1.833333            1.0           1.25            1.0   \n",
      "12083       1.833333            1.0           1.25            1.0   \n",
      "\n",
      "       AGEHHMEMCAT14  ...  2376  2377  2378  2379  2380  2381  2382  2383  \\\n",
      "DOEID                 ...                                                   \n",
      "1                  1  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n",
      "2                  1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
      "3                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
      "4                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
      "5                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
      "...              ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "12079              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "12080              1  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "12081              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "12082              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
      "12083              1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "       2384  2385  \n",
      "DOEID              \n",
      "1       0.0   0.0  \n",
      "2       0.0   0.0  \n",
      "3       0.0   0.0  \n",
      "4       0.0   0.0  \n",
      "5       0.0   0.0  \n",
      "...     ...   ...  \n",
      "12079   1.0   0.0  \n",
      "12080   0.0   0.0  \n",
      "12081   1.0   0.0  \n",
      "12082   0.0   0.0  \n",
      "12083   0.0   0.0  \n",
      "\n",
      "[9589 rows x 2592 columns]\n"
     ]
    }
   ],
   "source": [
    "#df_X = df_training.drop([\"KWH\"],axis =1)\n",
    "\n",
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
