{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#we start by creating a training and a test set\n",
    "#we will only use the test set when the model is complete in order to validate it\n",
    "\n",
    "df = pd.read_csv(\"recs2009_public.csv\")\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_training = df[msk]\n",
    "df_test = df[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 12 2 2471.68 4742 1080 4953 1271 4 3 'METRO' 'U' 1 -2 2004 7 8 -2\n",
      " -2 -2 -2 -2 1 5 -2 -2 20 -2 4 1 2 5 9 1 0 0 1 1 1 2 3 1 2 3 1 0 -2 -2 -2\n",
      " -2 -2 -2 -2 -2 -2 1 2 2 0 0 -2 -2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 5 0 -2 0 -2\n",
      " 3 1 1 1 3 1 1 2 0 -2 0 4 5 1 2 21 4 2 1 3 1 -2 -2 -2 21 4 2 12 3 1 -2 -2\n",
      " -2 -2 -2 -2 0 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 1 13 3 1 -2 -2 -2 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 2 2 3 3 2 1 1 0 -2 1 5 1 1 4 3 2 1 1 -2 0 1 0 0 1 1 0\n",
      " 3 4 3 4 3 4 1 1 -2 0 0 0 0 0 0 0 2 -2 2 -2 3 3 0 -2 0 0 0 0 0 1 0 0 3 -2\n",
      " 2 -2 1 2 1 1 3 0 1 1 1 3 0 1 -2 -2 -2 -2 -2 1 0 1 0 0 1 1 0 0 0 -2 -2 0 0\n",
      " 1 1 1 2 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 -2 -2\n",
      " -2 3 5 0 3 -2 -2 -2 0 0 0 0 -2 0 -2 0 0 -2 0 -2 0 -2 0 0 0 -2 -2 -2 0 -2\n",
      " 0 -2 -2 9 1 2 1 1 1 68 66 68 0 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 5 0 3 3 0 -2 -2 -2 -2 -2 -2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 -2 -2 1 -2 0 0 1 3 -2 0 -2 9 3 1 1 1 1 74 78 73 -2 -2 -2 -2 -2 -2\n",
      " -2 3 3 0 0 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -2 0\n",
      " -2 -2 0 -2 3 3 2 2 2 2 0 -2 -2 1 0 -2 1 1 41 2 3 -2 -2 1 1 2 0 -2 4 0 -2\n",
      " -2 -2 0 -2 -2 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 -2 1 1 1 1 1 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2\n",
      " -2 -2 -2 -2.0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 1 5 4 35 8 1 1 -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 0 0 0 -2 0 1 0 0 0 0 0\n",
      " 23 0 0 -2 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 5075 4675 3958 1118 3958 1118 0 0 0 0 0 0 3186.71 3068.8\n",
      " 2968.45 1515.5 7726.55 63006 10873.05 10470.73 10128.35 5170.9 26362.97\n",
      " 1315 226.93 218.54 211.39 107.92 550.22 0 0.0 0.0 0.0 0 0.0 0.0 0.0 0 0.0\n",
      " 0.0 0.0 0 0.0 0.0 0.0 0 0.0 0.0 0.0 0 0.0 0.0 0.0 0 0.0 0.0 0.0 0 0.0 0.0\n",
      " 0.0 0 0.0 0.0 0.0 0 0 0 0 0 0.0 0 0.0 0 0.0 0 0.0 0 0.0 63006 10873 10471\n",
      " 10128 5171 26363 1315 227 219 211 108 550 1 1 0 -2 -2 -2 -2 -2 -2 -2 -2\n",
      " -2 '4A' 2117 56 4250 0.48 6 56 9 96]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "#We now create dataframes for the input and output data of the model\n",
    "#I am assuming all other columns can be used as input, for simplicity.\n",
    "df_X = df_training.drop([\"KWH\"],axis =1) \n",
    "df_Y = df_training[\"KWH\"]\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "print(list(df_X.values)[0])\n",
    "#clf.fit(list(df_X.values), list(df_Y.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                            n_informative=2, n_redundant=0,\n",
    "                            random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "print(y)\n",
    "clf.fit(X, y)\n",
    "RandomForestClassifier(...)\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
