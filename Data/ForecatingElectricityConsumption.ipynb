{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/envs/Zesty/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (717,718) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KWH</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT10</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT11</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT12</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT13</th>\n",
       "      <th>AGEHHMEMCAT14</th>\n",
       "      <th>...</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOEID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18466</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5148</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2218</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2869</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>7647</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12080</th>\n",
       "      <td>1813</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12081</th>\n",
       "      <td>9834</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>4800</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>1764</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12083 rows Ã— 2592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         KWH  AGEHHMEMCAT10  AGEHHMEMCAT10  AGEHHMEMCAT11  AGEHHMEMCAT11  \\\n",
       "DOEID                                                                      \n",
       "1      18466       2.526316            1.0       2.181818            1.0   \n",
       "2       5148       2.526316            1.0       2.181818            1.0   \n",
       "3       2218       2.526316            1.0       2.181818            1.0   \n",
       "4      10015       2.526316            1.0       2.181818            1.0   \n",
       "5       2869       2.526316            1.0       2.181818            1.0   \n",
       "...      ...            ...            ...            ...            ...   \n",
       "12079   7647       2.526316            1.0       2.181818            1.0   \n",
       "12080   1813       2.526316            1.0       2.181818            1.0   \n",
       "12081   9834       2.526316            1.0       2.181818            1.0   \n",
       "12082   4800       2.526316            1.0       2.181818            1.0   \n",
       "12083   1764       2.526316            1.0       2.181818            1.0   \n",
       "\n",
       "       AGEHHMEMCAT12  AGEHHMEMCAT12  AGEHHMEMCAT13  AGEHHMEMCAT13  \\\n",
       "DOEID                                                               \n",
       "1           1.833333            1.0           1.25            1.0   \n",
       "2           1.833333            1.0           1.25            1.0   \n",
       "3           1.833333            1.0           1.25            1.0   \n",
       "4           1.833333            1.0           1.25            1.0   \n",
       "5           1.833333            1.0           1.25            1.0   \n",
       "...              ...            ...            ...            ...   \n",
       "12079       1.833333            1.0           1.25            1.0   \n",
       "12080       1.833333            1.0           1.25            1.0   \n",
       "12081       1.833333            1.0           1.25            1.0   \n",
       "12082       1.833333            1.0           1.25            1.0   \n",
       "12083       1.833333            1.0           1.25            1.0   \n",
       "\n",
       "       AGEHHMEMCAT14  ...  2376  2377  2378  2379  2380  2381  2382  2383  \\\n",
       "DOEID                 ...                                                   \n",
       "1                  1  ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n",
       "2                  1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "3                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "4                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "5                  1  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n",
       "...              ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "12079              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12080              1  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12081              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12082              1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "12083              1  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       2384  2385  \n",
       "DOEID              \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "5       0.0   0.0  \n",
       "...     ...   ...  \n",
       "12079   1.0   0.0  \n",
       "12080   0.0   0.0  \n",
       "12081   1.0   0.0  \n",
       "12082   0.0   0.0  \n",
       "12083   0.0   0.0  \n",
       "\n",
       "[12083 rows x 2592 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                            ###DATA PROCESSING\n",
    "#Many columns of the table have categorical data\n",
    "#We use One-hot econding schema to convert this data to binary\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv(\"recs2009_public.csv\",index_col=0)\n",
    "\n",
    "#There are many columns showing parameters like \"temperature when...\", but showing -2 when not aplicable.\n",
    "#We need to separate this type of data into a binary (not aplicable or aplicable) and a non-categorical column\n",
    "#In the non-categorical column, we will replace \"-2\" with the average of all the values different from \"-2\"\n",
    "\n",
    "def seriesIntoBinaryAndNonCateg(s,valuesToBinary):\n",
    "    mean = s[s > 0].mean()\n",
    "    nonCategSeries = s.replace(valuesToBinary,mean)\n",
    "    categSeriesList = [(s == value).astype(float) for value in valuesToBinary]\n",
    "    return pd.concat([nonCategSeries]+categSeriesList,axis=1)\n",
    "\n",
    "cols_categ_with_binary = set([21,22,26,29,38,41,44,48,54,146,152,310,460,462,466,467,468,540,546,547,548,549,\n",
    "                          600,602,716,723,776]+list(range(760,773)))\n",
    "list_all_noncateg_and_binary = list()\n",
    "for col in cols_categ_with_binary:\n",
    "    #I found columns with \".\" that I am assuming to mean \"again -2\"\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2))\n",
    "    list_all_noncateg_and_binary.append(seriesIntoBinaryAndNonCateg(s,[-2]))\n",
    "\n",
    "df_all_noncateg_and_binary = pd.concat(list_all_noncateg_and_binary,axis=1)\n",
    "\n",
    "#In the case of column \"NKRGALNC\", 77 means \"not sure\". thus we have values -2 and 77 to trasnform to binary\n",
    "#And a non-categorical integer\n",
    "#in the same way \n",
    "\n",
    "s = pd.to_numeric(df[df.columns[717]].replace('.',-2)) #asumming \".\" is \"-2\" to save time\n",
    "df_717 = seriesIntoBinaryAndNonCateg(s,[-2,77])\n",
    "\n",
    "#In a similar way, columns 595 597 599 601, can be trasnform into a non-categorical column and 3 binary columns \n",
    "#corresponding to values -2, -8, -9\n",
    "\n",
    "cols_noncateg_and_3_binaries = {595,597,599,601}\n",
    "list_all_noncateg_and_3_binaries = list()\n",
    "for col in cols_noncateg_and_3_binaries:\n",
    "    s = pd.to_numeric(df[df.columns[col]].replace('.',-2)) #asumming \".\" is \"-2\" to save time\n",
    "    list_all_noncateg_and_3_binaries.append(seriesIntoBinaryAndNonCateg(s,[-2,-8,-9]))\n",
    "\n",
    "df_all_noncateg_and_3_binaries = pd.concat(list_all_noncateg_and_3_binaries,axis=1)\n",
    "    \n",
    "# We create a list of fully non-categorical columns, as most columns are categorical\n",
    "cols_full_noncateg=set([4,5,6,7,8,15,30,31,32,33,113,115,117,133,238,288,502,503,556,594,596,598,607,758,759,784] \n",
    "                    +list(range(826,836))+list(range(856,918))+list(range(931,939)))\n",
    "df_full_noncateg=df[df.columns[list(cols_full_noncateg)]]\n",
    "# The gloal is predicting electricity usage from residential units so we remove all columns that\n",
    "# give direct information about electricity usage, and electricity cost 'KWHSPH'...'DOLELRFG'\n",
    "cols_to_ignore = set(range(839,856))\n",
    "\n",
    "#the raminig columns correspond to the full categorical ones\n",
    "cols_full_categ = [col for col in range(len(df.columns)) if col not in cols_categ_with_binary \\\n",
    "                     and col not in cols_full_noncateg and col not in cols_noncateg_and_3_binaries \\\n",
    "                     and col != 717 and col not in cols_to_ignore and col != 838] #838 is the column to be predcited\n",
    "\n",
    "#We now start with the actual One-hot econding schema\n",
    "df_categorical = df[df.columns[cols_full_categ]]\n",
    "X = df_categorical.to_numpy().tolist()\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X)\n",
    "Y = enc.transform(X).toarray()\n",
    "df_binary = pd.concat([pd.DataFrame(Y),pd.DataFrame(df.index)],axis =1).set_index(\"DOEID\")\n",
    "\n",
    "#finally concatenate all the dataframes\n",
    "df_encoded = pd.concat([df[df.columns[838]],df_all_noncateg_and_binary,df_717,df_all_noncateg_and_3_binaries,df_full_noncateg,df_binary],axis=1)\n",
    "df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.71% of the data correspond to the test set\n",
      "79.29% of the data correspond to the traning set\n"
     ]
    }
   ],
   "source": [
    "#we then create a training and a test set, using a random approach\n",
    "#we will only use the test set when the models are complete in order to validate it\n",
    "import numpy as np\n",
    "\n",
    "msk = np.random.rand(len(df_encoded)) < 0.8\n",
    "df_training = df_encoded[msk]\n",
    "df_test = df_encoded[~msk]\n",
    "\n",
    "testProcentageOfData = len(df_test.index)/(len(df_training.index)+len(df_test.index))*100\n",
    "traningProcentageofData = 100 - testProcentageOfData\n",
    "print(\"{:.2f}\".format(testProcentageOfData)+\"% of the data correspond to the test set\")\n",
    "print(\"{:.2f}\".format(traningProcentageofData)+\"% of the data correspond to the traning set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635.093131205496\n",
      "7646.1256048310315\n",
      "4930.778494156692\n"
     ]
    }
   ],
   "source": [
    "#Because of the nature of the data, I expect it to be stochastic to some extent. \n",
    "#Thus, we start using random forest because of its simplicity, \n",
    "#and then we will use MLP classifier with stochastic gradient descent.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#We now create dataframes for the input and output data of the model\n",
    "#I am assuming all other columns can be used as input, for simplicity.\n",
    "df_X = df_training.drop([\"KWH\"],axis =1) \n",
    "df_Y = df_training[\"KWH\"]\n",
    "clf = RandomForestClassifier(n_estimators = 110,max_depth=3,random_state=0, criterion=\"entropy\")\n",
    "clf.fit(df_X.to_numpy(), df_Y.to_numpy())\n",
    "\n",
    "prediction = clf.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "print(np.std(diff))\n",
    "print(np.std(df_test[\"KWH\"].to_numpy()))\n",
    "print(np.std(prediction))\n",
    "#print(np.std(df_test[\"KWH\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/envs/Zesty/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7631.863182755104\n",
      "7646.1256048310315\n",
      "650.726860672366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=30, solver = 'adam').fit(df_X.to_numpy(), df_Y.to_numpy())\n",
    "\n",
    "prediction = clf.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "print(np.std(diff))\n",
    "print(np.std(df_test[\"KWH\"].to_numpy()))\n",
    "print(np.std(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "array([[0.038..., 0.961...]])\n",
    "clf.predict(X_test[:5, :])\n",
    "array([1, 0, 1, 0, 1])\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(X, y)\n",
    "prediction = gpr.predict(df_test.drop([\"KWH\"],axis =1).to_numpy())\n",
    "diff = prediction-df_test[\"KWH\"].to_numpy()\n",
    "\n",
    "print(np.std(diff))\n",
    "print(np.std(df_test[\"KWH\"].to_numpy()))\n",
    "print(np.std(prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
